apiVersion: v1
data:
  relay: |
    connectors:
      spanmetrics: {}
    exporters:
      debug: {}
      opensearch:
        http:
          endpoint: http://opensearch:9200
          tls:
            insecure: true
        logs_index: otel-logs
        logs_index_time_format: yyyy-MM-dd
      otlp/jaeger:
        endpoint: jaeger:4317
        sending_queue:
          batch: null
        tls:
          insecure: true
      otlp/depviz-server:
        endpoint: depviz-server:4317
        tls:
          insecure: true
      otlphttp/prometheus:
        endpoint: http://prometheus:9090/api/v1/otlp
        sending_queue:
          batch: null
        tls:
          insecure: true
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      k8s_leader_elector/k8s_cluster:
        auth_type: serviceAccount
        lease_name: k8s.cluster.receiver.opentelemetry.io
        lease_namespace: default
      k8s_observer:
        auth_type: serviceAccount
        node: ${env:K8S_NODE_NAME}
    processors:
      batch: {}
      k8sattributes:
        extract:
          metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.pod.start_time
          - k8s.deployment.name
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.tag
          - container.image.name
          - k8s.cluster.uid
          - service.namespace
          - service.name
          - service.version
          - service.instance.id
          otel_annotations: true
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: connection
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
        - action: insert
          from_attribute: k8s.pod.uid
          key: service.instance.id
      resourcedetection:
        detectors:
        - env
        - system
      transform:
        error_mode: ignore
        trace_statements:
        - context: span
          statements:
          - replace_pattern(name, "\\?.*", "")
          - replace_match(name, "GET /api/products/*", "GET /api/products/{productId}")
    receivers:
      hostmetrics:
        collection_interval: 10s
        root_path: /hostfs
        scrapers:
          cpu: null
          disk: null
          filesystem:
            exclude_fs_types:
              fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
              match_type: strict
            exclude_mount_points:
              match_type: regexp
              mount_points:
              - /dev/*
              - /proc/*
              - /sys/*
              - /run/k3s/containerd/*
              - /var/lib/docker/*
              - /var/lib/kubelet/*
              - /snap/*
          load: null
          memory: null
          network: null
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      k8s_cluster:
        collection_interval: 10s
        k8s_leader_elector: k8s_leader_elector/k8s_cluster
      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 20s
        endpoint: ${env:K8S_NODE_IP}:10250
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            cors:
              allowed_origins:
              - http://*
              - https://*
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      receiver_creator/metrics:
        discovery:
          enabled: true
        watch_observers:
        - k8s_observer
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    service:
      extensions:
      - health_check
      - k8s_observer
      - k8s_leader_elector/k8s_cluster
      pipelines:
        logs:
          exporters:
          - opensearch
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resourcedetection
          - resource
          - batch
          receivers:
          - otlp
        metrics:
          exporters:
          - otlphttp/prometheus
          - debug
          processors:
          - k8sattributes
          - memory_limiter
          - resourcedetection
          - resource
          - batch
          receivers:
          - otlp
          - spanmetrics
          - receiver_creator/metrics
          - hostmetrics
          - kubeletstats
          - k8s_cluster
        traces:
          exporters:
          - otlp/jaeger
          - otlp/depviz-server
          - debug
          - spanmetrics
          processors:
          - k8sattributes
          - memory_limiter
          - resourcedetection
          - resource
          - transform
          - batch
          receivers:
          - otlp
          - jaeger
          - zipkin
      telemetry:
        metrics:
          level: detailed
          readers:
          - periodic:
              exporter:
                otlp:
                  endpoint: http://otel-collector:4318
                  insecure: true
                  protocol: http/protobuf
              interval: 10000
              timeout: 5000
kind: ConfigMap
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"relay":"connectors:\n  spanmetrics: {}\nexporters:\n  debug: {}\n  opensearch:\n    http:\n      endpoint: http://opensearch:9200\n      tls:\n        insecure: true\n    logs_index: otel-logs\n    logs_index_time_format: yyyy-MM-dd\n  otlp/jaeger:\n    endpoint: jaeger:4317\n    sending_queue:\n      batch: null\n    tls:\n      insecure: true\n  otlphttp/prometheus:\n    endpoint: http://prometheus:9090/api/v1/otlp\n    sending_queue:\n      batch: null\n    tls:\n      insecure: true\n  otlp/depviz:\n    endpoint: depviz:4317\n    sending_queue:\n      batch: null\n    tls:\n      insecure: true\nextensions:\n  health_check:\n    endpoint: ${env:MY_POD_IP}:13133\n  k8s_leader_elector/k8s_cluster:\n    auth_type: serviceAccount\n    lease_name: k8s.cluster.receiver.opentelemetry.io\n    lease_namespace: default\n  k8s_observer:\n    auth_type: serviceAccount\n    node: ${env:K8S_NODE_NAME}\nprocessors:\n  batch: {}\n  k8sattributes:\n    extract:\n      metadata:\n      - k8s.namespace.name\n      - k8s.pod.name\n      - k8s.pod.uid\n      - k8s.node.name\n      - k8s.pod.start_time\n      - k8s.deployment.name\n      - k8s.replicaset.name\n      - k8s.replicaset.uid\n      - k8s.daemonset.name\n      - k8s.daemonset.uid\n      - k8s.job.name\n      - k8s.job.uid\n      - k8s.container.name\n      - k8s.cronjob.name\n      - k8s.statefulset.name\n      - k8s.statefulset.uid\n      - container.image.tag\n      - container.image.name\n      - k8s.cluster.uid\n      - service.namespace\n      - service.name\n      - service.version\n      - service.instance.id\n      otel_annotations: true\n    filter:\n      node_from_env_var: K8S_NODE_NAME\n    passthrough: false\n    pod_association:\n    - sources:\n      - from: resource_attribute\n        name: k8s.pod.ip\n    - sources:\n      - from: resource_attribute\n        name: k8s.pod.uid\n    - sources:\n      - from: connection\n  memory_limiter:\n    check_interval: 5s\n    limit_percentage: 80\n    spike_limit_percentage: 25\n  resource:\n    attributes:\n    - action: insert\n      from_attribute: k8s.pod.uid\n      key: service.instance.id\n  resourcedetection:\n    detectors:\n    - env\n    - system\n  transform:\n    error_mode: ignore\n    trace_statements:\n    - context: span\n      statements:\n      - replace_pattern(name, \"\\\\?.*\", \"\")\n      - replace_match(name, \"GET /api/products/*\", \"GET /api/products/{productId}\")\nreceivers:\n  hostmetrics:\n    collection_interval: 10s\n    root_path: /hostfs\n    scrapers:\n      cpu: null\n      disk: null\n      filesystem:\n        exclude_fs_types:\n          fs_types:\n          - autofs\n          - binfmt_misc\n          - bpf\n          - cgroup2\n          - configfs\n          - debugfs\n          - devpts\n          - devtmpfs\n          - fusectl\n          - hugetlbfs\n          - iso9660\n          - mqueue\n          - nsfs\n          - overlay\n          - proc\n          - procfs\n          - pstore\n          - rpc_pipefs\n          - securityfs\n          - selinuxfs\n          - squashfs\n          - sysfs\n          - tracefs\n          match_type: strict\n        exclude_mount_points:\n          match_type: regexp\n          mount_points:\n          - /dev/*\n          - /proc/*\n          - /sys/*\n          - /run/k3s/containerd/*\n          - /var/lib/docker/*\n          - /var/lib/kubelet/*\n          - /snap/*\n      load: null\n      memory: null\n      network: null\n  jaeger:\n    protocols:\n      grpc:\n        endpoint: ${env:MY_POD_IP}:14250\n      thrift_compact:\n        endpoint: ${env:MY_POD_IP}:6831\n      thrift_http:\n        endpoint: ${env:MY_POD_IP}:14268\n  k8s_cluster:\n    collection_interval: 10s\n    k8s_leader_elector: k8s_leader_elector/k8s_cluster\n  kubeletstats:\n    auth_type: serviceAccount\n    collection_interval: 20s\n    endpoint: ${env:K8S_NODE_IP}:10250\n  otlp:\n    protocols:\n      grpc:\n        endpoint: ${env:MY_POD_IP}:4317\n      http:\n        cors:\n          allowed_origins:\n          - http://*\n          - https://*\n        endpoint: ${env:MY_POD_IP}:4318\n  prometheus:\n    config:\n      scrape_configs:\n      - job_name: opentelemetry-collector\n        scrape_interval: 10s\n        static_configs:\n        - targets:\n          - ${env:MY_POD_IP}:8888\n  receiver_creator/metrics:\n    discovery:\n      enabled: true\n    watch_observers:\n    - k8s_observer\n  zipkin:\n    endpoint: ${env:MY_POD_IP}:9411\nservice:\n  extensions:\n  - health_check\n  - k8s_observer\n  - k8s_leader_elector/k8s_cluster\n  pipelines:\n    logs:\n      exporters:\n      - opensearch\n      - debug\n      processors:\n      - k8sattributes\n      - memory_limiter\n      - resourcedetection\n      - resource\n      - batch\n      receivers:\n      - otlp\n    metrics:\n      exporters:\n      - otlphttp/prometheus\n      - debug\n      processors:\n      - k8sattributes\n      - memory_limiter\n      - resourcedetection\n      - resource\n      - batch\n      receivers:\n      - otlp\n      - spanmetrics\n      - receiver_creator/metrics\n      - hostmetrics\n      - kubeletstats\n      - k8s_cluster\n    traces:\n      exporters:\n      - otlp/jaeger\n      - debug\n      - spanmetrics\n      - otlp/depviz\n      processors:\n      - k8sattributes\n      - memory_limiter\n      - resourcedetection\n      - resource\n      - transform\n      - batch\n      receivers:\n      - otlp\n      - jaeger\n      - zipkin\n  telemetry:\n    metrics:\n      level: detailed\n      readers:\n      - periodic:\n          exporter:\n            otlp:\n              endpoint: http://otel-collector:4318\n              insecure: true\n              protocol: http/protobuf\n          interval: 10000\n          timeout: 5000\n"},"kind":"ConfigMap","metadata":{"annotations":{"meta.helm.sh/release-name":"my-otel-demo","meta.helm.sh/release-namespace":"default"},"creationTimestamp":"2026-02-19T03:19:06Z","labels":{"app.kubernetes.io/component":"agent-collector","app.kubernetes.io/instance":"my-otel-demo","app.kubernetes.io/managed-by":"Helm","app.kubernetes.io/name":"opentelemetry-collector","app.kubernetes.io/part-of":"opentelemetry-collector","app.kubernetes.io/version":"0.142.0","helm.sh/chart":"opentelemetry-collector-0.142.2"},"managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{"f:relay":{}},"f:metadata":{"f:annotations":{"f:meta.helm.sh/release-name":{},"f:meta.helm.sh/release-namespace":{}},"f:labels":{"f:app.kubernetes.io/component":{},"f:app.kubernetes.io/instance":{},"f:app.kubernetes.io/managed-by":{},"f:app.kubernetes.io/name":{},"f:app.kubernetes.io/part-of":{},"f:app.kubernetes.io/version":{},"f:helm.sh/chart":{}}}},"manager":"helm","operation":"Apply","time":"2026-02-19T03:19:06Z"}],"name":"otel-collector-agent","namespace":"default","resourceVersion":"899194","uid":"2704aade-5dd8-4afc-9a8e-da7be71790a9"}}
    meta.helm.sh/release-name: my-otel-demo
    meta.helm.sh/release-namespace: default
  creationTimestamp: "2026-02-19T03:19:06Z"
  labels:
    app.kubernetes.io/component: agent-collector
    app.kubernetes.io/instance: my-otel-demo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/part-of: opentelemetry-collector
    app.kubernetes.io/version: 0.142.0
    helm.sh/chart: opentelemetry-collector-0.142.2
  name: otel-collector-agent
  namespace: default
  resourceVersion: "928592"
  uid: 2704aade-5dd8-4afc-9a8e-da7be71790a9
